{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1h6m9VL/WxIWKT8FArs2Y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c189f64"
      },
      "source": [
        "# A Climate Change RAG Assistant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8016b818"
      },
      "source": [
        "## Set up the environment\n",
        "\n",
        "### Subtask:\n",
        "Install necessary libraries and set up API keys for any external services.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44eab1bd"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "695cee80",
        "outputId": "7ee63fa1-c7ac-4cd0-afd0-20200e377c41"
      },
      "source": [
        "# I'm installing the necessary libraries using pip.\n",
        "%pip install pandas transformers sentence-transformers chromadb langchain openai python-dotenv"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.7)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4a48bd2"
      },
      "source": [
        "**Reasoning**:\n",
        "Set up environment variables for the API key using python-dotenv.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b44720d3",
        "outputId": "7a485438-1fe0-43c4-af6f-e2494c35ce08"
      },
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# I'm loading environment variables from a .env file if it exists (optional).\n",
        "load_dotenv()\n",
        "\n",
        "# I'm using Colab's Secrets Manager for secure storage of API keys.\n",
        "from google.colab import userdata\n",
        "\n",
        "# I'm replacing 'OPENAI_API_KEY' with the actual name of my secret in Colab.\n",
        "# I need to ensure I have added my API key to the Secrets Manager with this name.\n",
        "try:\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"OPENAI_API_KEY loaded from Colab Secrets Manager.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"OPENAI_API_KEY not found in Colab Secrets Manager. Please add it.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading OPENAI_API_KEY from Colab Secrets Manager: {e}\")\n",
        "\n",
        "# I can add other API keys here following the same pattern\n",
        "# try:\n",
        "#     os.environ['ANOTHER_API_KEY'] = userdata.get('ANOTHER_API_KEY')\n",
        "#     print(\"ANOTHER_API_KEY loaded from Colab Secrets Manager.\")\n",
        "# except userdata.SecretNotFoundError:\n",
        "#     print(\"ANOTHER_API_KEY not found in Colab Secrets Manager. Please add it.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred while loading ANOTHER_API_KEY from Colab Secrets Manager: {e}\")\n",
        "\n",
        "print(\"Environment variable setup complete.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY not found in Colab Secrets Manager. Please add it.\n",
            "Environment variable setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6998ff1"
      },
      "source": [
        "## Load and process data\n",
        "\n",
        "### Subtask:\n",
        "Load the climate change data and process it for use in the RAG system. This may involve cleaning, tokenization, and creating embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e5e58f"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the climate change data from a suitable source. Since no specific data source is provided, I will use a placeholder dataset. I'll create a dummy pandas DataFrame to simulate loading data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7943c48c",
        "outputId": "c5f1a9d9-c8c4-4c1f-c961-71d7bbb9d7ea"
      },
      "source": [
        "# I'm installing the arxiv library to fetch climate change papers.\n",
        "%pip install arxiv"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.12/dist-packages (2.2.0)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.12/dist-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.12/dist-packages (from arxiv) (2.32.4)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2748e6a"
      },
      "source": [
        "Now, let's search for some climate change papers on arXiv and see how we can access their information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4832b32",
        "outputId": "c16639d6-c547-4da6-e3fc-e213ae7f019b"
      },
      "source": [
        "import arxiv\n",
        "\n",
        "# I'm searching for papers related to climate change.\n",
        "search = arxiv.Search(\n",
        "    query=\"climate change\",\n",
        "    max_results=10,\n",
        "    sort_by=arxiv.SortCriterion.Relevance\n",
        ")\n",
        "\n",
        "client = arxiv.Client()\n",
        "\n",
        "# I'm printing some information about the retrieved papers.\n",
        "for result in client.results(search):\n",
        "    print(f\"Title: {result.title}\")\n",
        "    print(f\"Authors: {', '.join(author.name for author in result.authors)}\")\n",
        "    print(f\"Summary: {result.summary[:200]}...\") # I'm printing the first 200 characters of the summary.\n",
        "    print(\"-\" * 20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: The structure of the climate debate\n",
            "Authors: Richard S. J. Tol\n",
            "Summary: First-best climate policy is a uniform carbon tax which gradually rises over\n",
            "time. Civil servants have complicated climate policy to expand bureaucracies,\n",
            "politicians to create rents. Environmentalist...\n",
            "--------------------\n",
            "Title: Climate Science and Control Engineering: Insights, Parallels, and Connections\n",
            "Authors: Salma M. Elsherif, Ahmad F. Taha\n",
            "Summary: Climate science is the multidisciplinary field that studies the Earth's\n",
            "climate and its evolution. At the very core of climate science are\n",
            "indispensable climate models that predict future climate scen...\n",
            "--------------------\n",
            "Title: Baumol's Climate Disease\n",
            "Authors: Fangzhi Wang, Hua Liao, Richard S. J. Tol\n",
            "Summary: We investigate optimal carbon abatement in a dynamic general equilibrium\n",
            "climate-economy model with endogenous structural change. By differentiating the\n",
            "production of investment from consumption, we s...\n",
            "--------------------\n",
            "Title: You are right. I am ALARMED -- But by Climate Change Counter Movement\n",
            "Authors: Shraey Bhatia, Jey Han Lau, Timothy Baldwin\n",
            "Summary: The world is facing the challenge of climate crisis. Despite the consensus in\n",
            "scientific community about anthropogenic global warming, the web is flooded\n",
            "with articles spreading climate misinformation...\n",
            "--------------------\n",
            "Title: Climate Change Conspiracy Theories on Social Media\n",
            "Authors: Aman Tyagi, Kathleen M. Carley\n",
            "Summary: One of the critical emerging challenges in climate change communication is\n",
            "the prevalence of conspiracy theories. This paper discusses some of the major\n",
            "conspiracy theories related to climate change f...\n",
            "--------------------\n",
            "Title: Hurricanes Increase Climate Change Conversations on Twitter\n",
            "Authors: Maddalena Torricelli, Max Falkenberg, Alessandro Galeazzi, Fabiana Zollo, Walter Quattrociocchi, Andrea Baronchelli\n",
            "Summary: The public understanding of climate change plays a critical role in\n",
            "translating climate science into climate action. In the public discourse,\n",
            "climate impacts are often discussed in the context of extr...\n",
            "--------------------\n",
            "Title: Trend and Thoughts: Understanding Climate Change Concern using Machine Learning and Social Media Data\n",
            "Authors: Zhongkai Shangguan, Zihe Zheng, Lei Lin\n",
            "Summary: Nowadays social media platforms such as Twitter provide a great opportunity\n",
            "to understand public opinion of climate change compared to traditional survey\n",
            "methods. In this paper, we constructed a massi...\n",
            "--------------------\n",
            "Title: Financial climate risk: a review of recent advances and key challenges\n",
            "Authors: Victor Cardenas\n",
            "Summary: The document provides an overview of financial climate risks. It delves into\n",
            "how climate change impacts the global financial system, distinguishing between\n",
            "physical risks (such as extreme weather even...\n",
            "--------------------\n",
            "Title: Mapping the Climate Change Landscape on TikTok\n",
            "Authors: Alessia Galdeman, Luca Maria Aiello\n",
            "Summary: Social media platforms shape climate action discourse. Mapping these online\n",
            "conversations is essential for effective communication strategies. TikTok's\n",
            "climate discussions are particularly relevant gi...\n",
            "--------------------\n",
            "Title: What shapes climate change perceptions in Africa? A random forest approach\n",
            "Authors: Juan B Gonzalez, Alfonso Sanchez\n",
            "Summary: Climate change perceptions are fundamental for adaptation and environmental\n",
            "policy support. Although Africa is one of the most vulnerable regions to\n",
            "climate change, little research has focused on how ...\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdf59ffc"
      },
      "source": [
        "### Subtask:\n",
        "Download the full text of the papers and create embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a027346f"
      },
      "source": [
        "**Reasoning**:\n",
        "Download the PDF of each paper retrieved from arXiv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78ed901c",
        "outputId": "b519913d-57b8-4ef0-8ffe-2ff2a734c355"
      },
      "source": [
        "import os\n",
        "\n",
        "download_folder = \"arxiv_climate_papers\"\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "\n",
        "# I'm downloading the PDF of each paper retrieved from arXiv.\n",
        "for result in client.results(search):\n",
        "    try:\n",
        "        result.download_pdf(dirpath=download_folder)\n",
        "        print(f\"Downloaded {result.title}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not download {result.title}: {e}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded The structure of the climate debate\n",
            "Downloaded Climate Science and Control Engineering: Insights, Parallels, and Connections\n",
            "Downloaded Baumol's Climate Disease\n",
            "Downloaded You are right. I am ALARMED -- But by Climate Change Counter Movement\n",
            "Downloaded Climate Change Conspiracy Theories on Social Media\n",
            "Downloaded Hurricanes Increase Climate Change Conversations on Twitter\n",
            "Downloaded Trend and Thoughts: Understanding Climate Change Concern using Machine Learning and Social Media Data\n",
            "Downloaded Financial climate risk: a review of recent advances and key challenges\n",
            "Downloaded Mapping the Climate Change Landscape on TikTok\n",
            "Downloaded What shapes climate change perceptions in Africa? A random forest approach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023dbe28",
        "outputId": "db79479e-37cc-45dd-d80e-6f7ef3b92632"
      },
      "source": [
        "# I'm installing pymupdf to extract text from PDFs.\n",
        "%pip install pymupdf"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "722af3f4"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract text from the downloaded PDF files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6928f56",
        "outputId": "50f41da4-3dc9-4150-dd75-0468158464a1"
      },
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not extract text from {pdf_path}: {e}\")\n",
        "        return None\n",
        "    return text\n",
        "\n",
        "climate_texts = []\n",
        "download_folder = \"arxiv_climate_papers\"\n",
        "\n",
        "# I'm extracting text from the downloaded PDF files.\n",
        "for filename in os.listdir(download_folder):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(download_folder, filename)\n",
        "        print(f\"Extracting text from {filename}...\")\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        if text:\n",
        "            climate_texts.append({\"filename\": filename, \"text\": text})\n",
        "\n",
        "print(f\"Extracted text from {len(climate_texts)} files.\")\n",
        "# I can inspect the extracted text from the first file\n",
        "# if climate_texts:\n",
        "#     print(\"\\n--- My first extracted text sample ---\")\n",
        "#     print(climate_texts[0]['text'][:500]) # I'm printing the first 500 characters."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text from 2312.00160v1.Baumol_s_Climate_Disease.pdf...\n",
            "Extracting text from 2111.14929v1.Trend_and_Thoughts__Understanding_Climate_Change_Concern_using_Machine_Learning_and_Social_Media_Data.pdf...\n",
            "Extracting text from 2004.14907v1.You_are_right__I_am_ALARMED____But_by_Climate_Change_Counter_Movement.pdf...\n",
            "Extracting text from 2105.07867v1.What_shapes_climate_change_perceptions_in_Africa__A_random_forest_approach.pdf...\n",
            "Extracting text from 2504.21153v2.Climate_Science_and_Control_Engineering__Insights__Parallels__and_Connections.pdf...\n",
            "Extracting text from 2404.07331v1.Financial_climate_risk__a_review_of_recent_advances_and_key_challenges.pdf...\n",
            "Extracting text from 2505.03813v1.Mapping_the_Climate_Change_Landscape_on_TikTok.pdf...\n",
            "Extracting text from 1608.05597v1.The_structure_of_the_climate_debate.pdf...\n",
            "Extracting text from 2305.07529v1.Hurricanes_Increase_Climate_Change_Conversations_on_Twitter.pdf...\n",
            "Extracting text from 2107.03318v1.Climate_Change_Conspiracy_Theories_on_Social_Media.pdf...\n",
            "Extracted text from 10 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46885c4a"
      },
      "source": [
        "**Reasoning**:\n",
        "Create embeddings from the extracted text using a pre-trained sentence transformer model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b37c894",
        "outputId": "03953193-20e6-470a-8277-333e2a6a835c"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# I'm loading a pre-trained sentence transformer model.\n",
        "# 'all-MiniLM-L6-v2' is a good general-purpose model I'm using.\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# I'm generating embeddings for the extracted texts.\n",
        "# I'll store the embeddings along with the text and filename.\n",
        "for item in climate_texts:\n",
        "    item['embedding'] = model.encode(item['text'])\n",
        "\n",
        "print(f\"Generated embeddings for {len(climate_texts)} texts.\")\n",
        "# I can inspect the first embedding\n",
        "# if climate_texts:\n",
        "#     print(\"\\n--- My first embedding sample ---\")\n",
        "#     print(climate_texts[0]['embedding'][:10]) # I'm printing the first 10 values of the embedding."
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated embeddings for 10 texts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba7e1e0d"
      },
      "source": [
        "## Build the RAG system\n",
        "\n",
        "### Subtask:\n",
        "Set up a vector database and add the extracted text and embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f83c75aa"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize ChromaDB and create a collection to store the embeddings and associated text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1446a16",
        "outputId": "8812044d-2c8b-4da7-85b9-f4435efc2d76"
      },
      "source": [
        "import chromadb\n",
        "\n",
        "# I'm initializing the ChromaDB client (in-memory for this example).\n",
        "client = chromadb.Client()\n",
        "\n",
        "# I'm creating a collection (or getting an existing one).\n",
        "# This is where I'll store my embeddings, documents, and metadata.\n",
        "collection_name = \"climate_change_papers\"\n",
        "try:\n",
        "    collection = client.create_collection(name=collection_name)\n",
        "    print(f\"Collection '{collection_name}' created.\")\n",
        "except: # I'm handling the case if the collection already exists.\n",
        "    collection = client.get_collection(name=collection_name)\n",
        "    print(f\"Collection '{collection_name}' already exists. Using existing collection.\")\n",
        "\n",
        "\n",
        "# I'm preparing data for adding to ChromaDB.\n",
        "# ChromaDB requires ids, embeddings, and documents (original text).\n",
        "# I'll use the filename as the id for simplicity.\n",
        "ids = [item['filename'] for item in climate_texts]\n",
        "embeddings = [item['embedding'].tolist() for item in climate_texts] # I'm converting numpy arrays to lists.\n",
        "documents = [item['text'] for item in climate_texts]\n",
        "\n",
        "# I'm adding data to the collection.\n",
        "collection.add(\n",
        "    embeddings=embeddings,\n",
        "    documents=documents,\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "print(f\"Added {len(climate_texts)} documents to the collection.\")\n",
        "print(f\"Collection count: {collection.count()}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'climate_change_papers' already exists. Using existing collection.\n",
            "Added 10 documents to the collection.\n",
            "Collection count: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3872651"
      },
      "source": [
        "### Subtask:\n",
        "Implement the retrieval mechanism to find relevant documents based on a query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8835e1b"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement a function to perform a similarity search on the ChromaDB collection using a query embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1df62444",
        "outputId": "45bd937e-791a-4da9-9ece-5b910c593351"
      },
      "source": [
        "# I'm implementing a function to perform a similarity search on the ChromaDB collection.\n",
        "from sentence_transformers import SentenceTransformer # I need this import if this cell is run independently\n",
        "\n",
        "def retrieve_documents(query, collection, model, n_results=5):\n",
        "    \"\"\"\n",
        "    Retrieves relevant documents from my ChromaDB collection based on a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's query.\n",
        "        collection (chromadb.Collection): The ChromaDB collection to search.\n",
        "        model (SentenceTransformer): The sentence transformer model for generating query embeddings.\n",
        "        n_results (int): The number of most relevant documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary contains the document ID,\n",
        "              text, and distance for the retrieved documents.\n",
        "    \"\"\"\n",
        "    # I'm generating an embedding for the query.\n",
        "    query_embedding = model.encode(query).tolist()\n",
        "\n",
        "    # I'm performing a similarity search in ChromaDB.\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results,\n",
        "        include=['documents', 'distances'] # I'm including document text and similarity distances.\n",
        "    )\n",
        "\n",
        "    # I'm formatting the results.\n",
        "    retrieved_docs = []\n",
        "    if results and results['ids'] and results['documents']:\n",
        "        for i in range(len(results['ids'][0])):\n",
        "            retrieved_docs.append({\n",
        "                'id': results['ids'][0][i],\n",
        "                'text': results['documents'][0][i],\n",
        "                'distance': results['distances'][0][i]\n",
        "            })\n",
        "    return retrieved_docs\n",
        "\n",
        "# Example usage:\n",
        "query = \"What are the financial risks of climate change?\"\n",
        "retrieved_documents = retrieve_documents(query, collection, model)\n",
        "\n",
        "print(f\"I'm retrieving documents for query: '{query}'\")\n",
        "for doc in retrieved_documents:\n",
        "    print(f\"--- Document ID: {doc['id']} (Distance: {doc['distance']}) ---\")\n",
        "    print(f\"{doc['text'][:500]}...\") # I'm printing the first 500 characters of the retrieved text.\n",
        "    print(\"-\" * 50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm retrieving documents for query: 'What are the financial risks of climate change?'\n",
            "--- Document ID: 2404.07331v1.Financial_climate_risk__a_review_of_recent_advances_and_key_challenges.pdf (Distance: 0.6765998601913452) ---\n",
            "Institute for Resources, Enviroment and Sustainability, UBC \n",
            " \n",
            " \n",
            " \n",
            "1 \n",
            "Financial climate risk: a review of recent advances and \n",
            "key challenges \n",
            " \n",
            "Victor Cardenas* \n",
            " \n",
            "*Institute for Resources, Enviroment and Sustainability, University of British Columbia \n",
            " \n",
            "Abstract- The document provides an overview of financial climate risks. It delves into how climate change impacts the global financial \n",
            "system, distinguishing between physical risks (such as extreme weather events) and transition risks (stemmin...\n",
            "--------------------------------------------------\n",
            "--- Document ID: 2105.07867v1.What_shapes_climate_change_perceptions_in_Africa__A_random_forest_approach.pdf (Distance: 0.9767863750457764) ---\n",
            " \n",
            "1 \n",
            "Original Manuscript \n",
            "[What shapes climate change perceptions in Africa? A random forest approach] \n",
            "[Juan B González1*, Alfonso Sanchez2] \n",
            "[1 Department of Economics, Universidad Loyola, Dos Hermanas, Spain.  \n",
            "2 Department of International Studies, Universidad Loyola, Dos Hermanas, Spain.] \n",
            "Corresponding author: Juan B González \n",
            "* juanbgonzalezblanco@gmail.com \n",
            " \n",
            " \n",
            "2 \n",
            "Abstract \n",
            "Climate change perceptions are fundamental for adaptation and environmental policy \n",
            "support. Although Africa is one...\n",
            "--------------------------------------------------\n",
            "--- Document ID: 1608.05597v1.The_structure_of_the_climate_debate.pdf (Distance: 0.9965262413024902) ---\n",
            "THE STRUCTURE OF THE CLIMATE DEBATE \n",
            " \n",
            "Richard S.J. Tol \n",
            "Department of Economics, University of Sussex, Falmer, United Kingdom \n",
            "Institute for Environmental Studies, Vrije Universiteit, Amsterdam, The Netherlands \n",
            "Department of Spatial Economics, Vrije Universiteit, Amsterdam, The Netherlands \n",
            "Tinbergen Institute, Amsterdam, The Netherlands \n",
            "CESifo, Munich, Germany \n",
            " \n",
            "19 August 2016 \n",
            " \n",
            "Abstract \n",
            "First-best climate policy is a uniform carbon tax which gradually rises over time. Civil \n",
            "servants hav...\n",
            "--------------------------------------------------\n",
            "--- Document ID: 2312.00160v1.Baumol_s_Climate_Disease.pdf (Distance: 0.9973188638687134) ---\n",
            "Baumol’s climate disease\n",
            "Fangzhi Wanga,b, Hua Liaoa,b, Richard S.J. Tolc,d,e,f,g,h,i\n",
            "aSchool of Management and Economics, Beijing Institute of\n",
            "Technology, Beijing, 100081, China\n",
            "bCenter for Energy and Environmental Policy Research, Beijing Institute of\n",
            "Technology, Beijing, 100081, China\n",
            "cDepartment of Economics, University of Sussex, Falmer, BN1 9RH, UK\n",
            "dInstitute for Environmental Studies, Vrije Universiteit, Amsterdam, the Netherlands\n",
            "eDepartment of Spatial Economics, Vrije Universiteit, Amste...\n",
            "--------------------------------------------------\n",
            "--- Document ID: 2305.07529v1.Hurricanes_Increase_Climate_Change_Conversations_on_Twitter.pdf (Distance: 1.160664439201355) ---\n",
            "arXiv:2305.07529v1  [physics.soc-ph]  12 May 2023\n",
            "Hurricanes Increase Climate Change Conversations\n",
            "on Twitter\n",
            "Maddalena Torricelli1, Max Falkenberg1, Alessandro\n",
            "Galeazzi2, Fabiana Zollo2,3, Walter Quattrociocchi4, Andrea\n",
            "Baronchelli1,5,*\n",
            "1 City University of London, Department of Mathematics, London EC1V 0HB (UK)\n",
            "2 Ca’ Foscari University of Venice — Department of Environmental Sciences, Informatics and\n",
            "Statistics, Via Torino 155, 30172 Venezia (IT)\n",
            "3 The New Institute Centre for Environmental Hu...\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84efcbdd"
      },
      "source": [
        "### Subtask:\n",
        "Implement the generation mechanism to answer questions based on retrieved documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "394f9336"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement a function to generate a response using the OpenAI API based on the user query and retrieved documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7267493"
      },
      "source": [
        "## Using Google Generative AI API (Gemini)\n",
        "\n",
        "You'll need to get an API key from Google AI Studio and add it to your Colab Secrets Manager.\n",
        "\n",
        "### Subtask:\n",
        "Set up the Google Generative AI API key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08498ea1",
        "outputId": "0558704b-81a5-4185-cdfb-1919367fb611"
      },
      "source": [
        "# I'm installing the Google Generative AI library.\n",
        "%pip install google-generativeai"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.179.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f60adcf"
      },
      "source": [
        "**Reasoning**:\n",
        "Set up the Google Generative AI API key using Colab's Secrets Manager."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed81ed2c",
        "outputId": "54005a98-8b68-4529-9b4c-907b0be228e4"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# I'm using Colab's Secrets Manager for secure storage of API keys.\n",
        "# I'm replacing 'GOOGLE_API_KEY' with the actual name of my secret in Colab.\n",
        "# I need to ensure I have added my API key to the Secrets Manager with this name.\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"Google Generative AI API key loaded from Colab Secrets Manager.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"GOOGLE_API_KEY not found in Colab Secrets Manager. Please add it.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading GOOGLE_API_KEY from Colab Secrets Manager: {e}\")\n",
        "\n",
        "print(\"Google Generative AI environment variable setup complete.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Generative AI API key loaded from Colab Secrets Manager.\n",
            "Google Generative AI environment variable setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "922d73db"
      },
      "source": [
        "### Subtask:\n",
        "Update the `generate_answer` function to use the Google Generative AI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84eac0dc"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `generate_answer` function to use the `google.generativeai` library instead of the `openai` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "c70f6fef",
        "outputId": "6b37236a-0d69-4f98-c445-db49254c537d"
      },
      "source": [
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer # I need this import if this cell is run independently\n",
        "import chromadb # I need this import if this cell is run independently\n",
        "\n",
        "# I'm assuming 'model' and 'collection' are defined from previous cells\n",
        "# And GOOGLE_API_KEY has been loaded and genai.configure() has been called\n",
        "\n",
        "def generate_answer_gemini(query, retrieved_documents):\n",
        "    \"\"\"\n",
        "    Generates an answer to the query based on the retrieved documents using Google's Gemini model.\n",
        "    \"\"\"\n",
        "    if not retrieved_documents:\n",
        "        return \"I could not find any relevant information to answer your question.\"\n",
        "\n",
        "    # I'm combining the retrieved document texts into a single context.\n",
        "    context = \"\\n---\\n\".join([doc['text'] for doc in retrieved_documents])\n",
        "\n",
        "    try:\n",
        "        # I'm initializing the Gemini model.\n",
        "        # I can choose a different model if needed, e.g., 'gemini-pro'.\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "        # I'm crafting the prompt for the language model.\n",
        "        # I'm instructing the model to answer based only on the provided context.\n",
        "        prompt = f\"\"\"Answer the following question based on the context below:\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "        # I'm calling the Gemini API to generate the answer.\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during text generation with Gemini: {e}\")\n",
        "        return \"Sorry, I could not generate an answer at this time.\"\n",
        "\n",
        "# Example usage with the Gemini API:\n",
        "query = \"What are the financial risks of climate change?\"\n",
        "\n",
        "# I'm re-running the document retrieval step to ensure retrieved_documents is defined.\n",
        "# I'm assuming 'collection' and 'model' are still defined from previous steps.\n",
        "print(f\"I'm retrieving documents for query: '{query}' before generating answer with Gemini...\")\n",
        "retrieved_documents = retrieve_documents(query, collection, model) # I'm using the existing retrieve_documents function.\n",
        "\n",
        "# I'm generating the answer using my new function.\n",
        "generated_answer_gemini = generate_answer_gemini(query, retrieved_documents)\n",
        "\n",
        "print(\"\\n--- My Generated Answer (Gemini) ---\")\n",
        "print(generated_answer_gemini)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm retrieving documents for query: 'What are the financial risks of climate change?' before generating answer with Gemini...\n",
            "\n",
            "--- My Generated Answer (Gemini) ---\n",
            "Based on the provided text, the financial risks of climate change are multifaceted and include:\n",
            "\n",
            "**Physical Risks:** These are the direct consequences of climate change, such as extreme weather events (catastrophic floods, hurricanes, wildfires), rising sea levels, and shifts in weather patterns.  These can lead to:\n",
            "\n",
            "* **Increased non-performing loans (NPLs):** Severe climate and environmental disasters can cause borrowers to default on loans, impacting the banking sector.\n",
            "* **Physical damages:** Damage to property, infrastructure, and land leading to business disruption, asset destruction, and the need for reconstruction or replacement.  This affects various sectors, including banking, insurance, and real estate.\n",
            "* **Increased insured damages:** Higher insurance claims due to increased frequency and severity of climate-related disasters.\n",
            "* **Disruption of business operations:**  Interruption of supply chains and business operations leading to economic losses.\n",
            "* **Reduced value of assets:** Decrease in the value of assets due to climate-related damage or obsolescence (stranded assets, e.g., fossil fuel power plants).\n",
            "\n",
            "\n",
            "**Transition Risks:** These stem from the adjustments needed to move toward a lower-carbon economy.  These include risks associated with:\n",
            "\n",
            "* **Policy changes:** New regulations and policies aimed at reducing emissions can impact business models and economic performance, potentially leading to financial losses.\n",
            "* **Technological advancements:** Shifts in market preferences and technology can affect the value of existing assets and the competitiveness of certain industries.\n",
            "* **Market shifts:** Changes in consumer preferences and investor sentiment can lead to decreased asset values and funding challenges for carbon-intensive industries.\n",
            "* **Reputational impacts:** Companies with poor environmental performance can suffer reputational damage, negatively impacting their stock price and access to capital.\n",
            "* **Liability risk:** Potential financial losses from legal claims related to climate change impacts.\n",
            "\n",
            "\n",
            "The text also highlights that poverty exacerbates vulnerability to climate change, making populations in developing countries particularly susceptible to these financial risks.  Microfinance institutions (MFIs), often the primary source of financing for vulnerable populations, need to update their risk management practices to explicitly incorporate climate risk assessments.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6c200e0"
      },
      "source": [
        "## Build the RAG Application\n",
        "\n",
        "### Subtask:\n",
        "Integrate the retrieval and generation components to create the RAG application workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b192149"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine the `retrieve_documents` and `generate_answer_gemini` functions into a single function that takes a query and returns a generated answer using the RAG approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "bf8eb645",
        "outputId": "976ed9da-1c77-4b60-c4b4-f36e0a6a4742"
      },
      "source": [
        "# I'm combining the retrieval and generation components into a single function.\n",
        "def rag_answer_query(query, collection, model):\n",
        "    \"\"\"\n",
        "    Answers a user query using the RAG approach.\n",
        "    \"\"\"\n",
        "    # 1. I'm retrieving relevant documents.\n",
        "    print(f\"Retrieving documents for query: '{query}'...\")\n",
        "    retrieved_documents = retrieve_documents(query, collection, model)\n",
        "\n",
        "    # 2. I'm generating an answer based on retrieved documents.\n",
        "    print(\"Generating answer based on retrieved documents...\")\n",
        "    generated_answer = generate_answer_gemini(query, retrieved_documents)\n",
        "\n",
        "    return generated_answer\n",
        "\n",
        "# Example usage of my integrated RAG function:\n",
        "query = \"What is the impact of hurricanes on climate change conversations?\"\n",
        "rag_response = rag_answer_query(query, collection, model)\n",
        "\n",
        "print(\"\\n--- My RAG Application Response ---\")\n",
        "print(rag_response)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving documents for query: 'What is the impact of hurricanes on climate change conversations?'...\n",
            "Generating answer based on retrieved documents...\n",
            "\n",
            "--- My RAG Application Response ---\n",
            "Based on the provided text, hurricanes significantly increase conversations about climate change on Twitter.  The study shows an average 80% increase in climate change-related tweets in regions affected by hurricanes, with increases up to 200% for the most damaging hurricanes.  This heightened online discussion, however, is both geographically and temporally limited, with a rapid decay in public attention in the weeks following the event.  The study also highlights that news media coverage of hurricanes frequently includes climate change as a prominent topic, although the language used varies between reliable and questionable sources.  Reliable sources use \"climate change\" more often, while less reliable sources favor terms like \"global warming\" and \"weather,\" sometimes even referencing conspiracy theories.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bae75854"
      },
      "source": [
        "## Interactive RAG Assistant\n",
        "\n",
        "### Subtask:\n",
        "Create a simple interactive loop to test the RAG assistant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c228f920"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement a loop that prompts the user for a query, calls the `rag_answer_query` function, and prints the generated answer until the user types 'quit'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "fb0d4107",
        "outputId": "da17ab6e-ad7d-474f-b0ea-a6808233b1e9"
      },
      "source": [
        "# I'm starting the interactive loop for testing.\n",
        "print(\"Climate Change RAG Assistant. Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_query = input(\"\\nEnter your query: \")\n",
        "    if user_query.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    # I'm getting the answer from my RAG assistant.\n",
        "    answer = rag_answer_query(user_query, collection, model)\n",
        "\n",
        "    print(\"\\n--- My RAG Assistant's Answer ---\")\n",
        "    print(answer)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "print(\"Exiting RAG Assistant.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Climate Change RAG Assistant. Type 'quit' to exit.\n",
            "\n",
            "Enter your query: what is the future of climate change?\n",
            "Retrieving documents for query: 'what is the future of climate change?'...\n",
            "Generating answer based on retrieved documents...\n",
            "\n",
            "--- My RAG Assistant's Answer ---\n",
            "The provided text offers several perspectives on the future of climate change, but doesn't offer a singular prediction.  \n",
            "\n",
            "Richard Tol's paper (2016) suggests that the climate debate will become more constructive due to factors such as the Paris Agreement shifting focus back to national governments, changing political priorities, austerity measures, and a maturing bureaucracy.  He believes a modest carbon tax is a feasible solution.\n",
            "\n",
            "The second paper (2023) focuses on the impact of hurricanes on public awareness of climate change.  It finds that while hurricanes significantly increase online discussions about climate change in affected areas, this heightened awareness is temporary.  This implies a need for sustained efforts to maintain public engagement with the issue.\n",
            "\n",
            "The third paper (2025) introduces climate science to control engineering researchers, highlighting the potential of applying control theory principles to climate models.  It focuses on using this framework to enhance modeling, prediction, and strategic intervention for climate mitigation.  The authors do not claim their approach will solve climate problems, but propose it as a new perspective.\n",
            "\n",
            "The final paper (date not specified) uses Afrobarometer data to analyze climate change perceptions in Africa. The study shows perceived agricultural conditions, long-term weather changes, education, access to information, and ideology as strong predictors of climate change perceptions. This research highlights the importance of tailoring climate change communication to the African context for effective adaptation and mitigation efforts.\n",
            "\n",
            "In summary, the future of climate change as depicted by these papers involves a complex interplay between political and social factors, public awareness influenced by events, and the potential application of new modeling and analytical techniques.  There is no single \"future\" predicted, but rather a set of potential trajectories depending on these interacting influences.\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Enter your query: quit\n",
            "Exiting RAG Assistant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d93a8b7"
      },
      "source": [
        "# I'm providing instructions for running the Streamlit app locally.\n",
        "\n",
        "# Now I have two files: app.py which contains the Streamlit application code,\n",
        "# and requirements.txt which lists the necessary Python libraries.\n",
        "\n",
        "# To run this Streamlit application locally:\n",
        "\n",
        "# 1. Save the files: Make sure app.py and requirements.txt are saved in the same directory on my local machine.\n",
        "# 2. Install dependencies: Open a terminal or command prompt in that directory and run:\n",
        "#    pip install -r requirements.txt\n",
        "# 3. Set your Google API Key as an environment variable. Use the appropriate command for your operating system,\n",
        "#    replacing 'YOUR_API_KEY' with your actual API key:\n",
        "\n",
        "#    For macOS and Linux:\n",
        "#    export GOOGLE_API_KEY='YOUR_API_KEY'\n",
        "\n",
        "#    For Windows Command Prompt:\n",
        "#    set GOOGLE_API_KEY='YOUR_API_KEY'\n",
        "\n",
        "#    For Windows PowerShell:\n",
        "#    $env:GOOGLE_API_KEY='YOUR_API_KEY'\n",
        "\n",
        "# 4. Run the Streamlit application:\n",
        "#    streamlit run app.py\n",
        "\n",
        "# This will start the Streamlit development server, and my web application will open in my browser."
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}